---
title: "Machine Learning: Classification"
topic: true
subjects: ['R']
draft: false
subjects_weight: 41
---

## Contents

- k-Nearest Neighbours (kNN)
	- How it works
	- Finding a good value for k
	- Importance of normalising data
- Naive Bayes
	- Background on Bayesian Methods
	- Probabilistic model
	- Model evaluation (accuracy, confusion matrix, precision and recall)
	- Flavours of Naive Bayes
	- Laplace smoothing
	- Document Classifier
- Model Evaluation
	* Confusion Matrix
	* Accuracy
	* Sensitivity
	* Precision
	* Specificity
	* Positive/Negative Predictive Value
	* F Measure
	* ROC and AUC
- Costs of Errors
- Decision Trees
	- Recursive Partitioning algorithm
	- Pruning
	- Model parameters (preventing underfitting and overfitting)
	- A variation: Conditional Inference Trees
- Logistic Regression
	* Odds, Log Odds and the Logit Function
	* Example: Synthetic Data
	* Principle of Parsimony
	* Multicollinearity
	* Example: Myopia Data
- Support Vector Machine
	- Maximum Margin Classifiers
	- Support Vector Classifiers
	- The Kernel Trick
	- Non-Linear Boundaries
		* Polynomial Kernel
		* Radial Kernel
- Unbalanced Data
	* Oversampling
	* Undersampling
	* Synthetic Data Generation
